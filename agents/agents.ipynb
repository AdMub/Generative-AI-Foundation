{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff6b4041",
   "metadata": {},
   "source": [
    "### **Library analogy (one-sentence)**\n",
    "\n",
    "You have a set of tool-helpers (Wikipedia, arXiv, a local web crawler and a vector DB). An agent is a smart librarian that can call those tools, fetch sources, and then use a writer (LLM) to answer user questions by combining tool outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "866faec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: arxiv in c:\\users\\user\\anaconda3\\envs\\texts\\lib\\site-packages (2.2.0)\n",
      "Requirement already satisfied: feedparser~=6.0.10 in c:\\users\\user\\anaconda3\\envs\\texts\\lib\\site-packages (from arxiv) (6.0.12)\n",
      "Requirement already satisfied: requests~=2.32.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from arxiv) (2.32.5)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\user\\anaconda3\\envs\\texts\\lib\\site-packages (from feedparser~=6.0.10->arxiv) (1.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests~=2.32.0->arxiv) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests~=2.32.0->arxiv) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests~=2.32.0->arxiv) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests~=2.32.0->arxiv) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install arxiv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afed9dfc",
   "metadata": {},
   "source": [
    "- **What it does:** Installs the Python package to query arXiv (research-paper search).\n",
    "- **Analogy:** Buying a subscription so the librarian can look up the latest research."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb94b4fa",
   "metadata": {},
   "source": [
    "#### **Wikipedia tool + utility**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "042b0e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wikipedia in c:\\users\\user\\anaconda3\\envs\\texts\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\anaconda3\\envs\\texts\\lib\\site-packages (from wikipedia) (4.14.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from wikipedia) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.10.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\anaconda3\\envs\\texts\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from beautifulsoup4->wikipedia) (4.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71a3c3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6f23a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper=WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
    "wiki=WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "65d9fc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6602b9f6",
   "metadata": {},
   "source": [
    "- **What it does:** Creates a Wikipedia tool that will fetch up to 1 result and returns up to 200 characters per doc. `wiki` is the tool the agent can call.\n",
    "- **Analogy:** A fast encyclopedia lookup the librarian can consult."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae1394a",
   "metadata": {},
   "source": [
    "#### **Web page loader + splitting + embeddings + vector DB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1c06d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000020FE7300440>, search_kwargs={})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs=loader.load()\n",
    "documents=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200).split_documents(docs)\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")  # fast embedding model\n",
    "#vectordb=FAISS.from_documents(documents,OpenAIEmbeddings())\n",
    "vectordb=FAISS.from_documents(documents,embeddings)\n",
    "retriever=vectordb.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb1f906",
   "metadata": {},
   "source": [
    "- **What it does:**\n",
    "    - Loads the LangChain docs web page, splits the text into chunks (1000 characters each, 200 overlap), converts chunks into embeddings (fingerprints) using an Ollama embedding model, stores them in FAISS, and creates a `retriever` you can query for similar chunks.\n",
    "\n",
    "- **Analogy:** The librarian photocopies pages, labels them with searchable fingerprints, and stores them in a fast cabinet for quick lookup.\n",
    "\n",
    "- **Important note:** You correctly commented out the OpenAI embedding line. Keep using a dedicated embedding model like `nomic-embed-text`. Don’t use a chat LLM for embeddings — it’s slow and expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cad07f3",
   "metadata": {},
   "source": [
    "#### **Convert retriever into a tool:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93d88c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retriever_tool=create_retriever_tool(retriever,\"langsmith_search\",\n",
    "                      \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a252d27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith_search'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c3604c",
   "metadata": {},
   "source": [
    "- What it does: Wraps your retriever into a tool with a name and description so the agent can call it.\n",
    "- Analogy: The librarian has a special drawer labeled “LangSmith docs” they can open and search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883b3dbd",
   "metadata": {},
   "source": [
    "#### **Arxiv Tool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dedf915f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arxiv'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Arxiv Tool\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "arxiv_wrapper=ArxivAPIWrapper(top_k_results=1, doc_content_chars_max=200)\n",
    "arxiv=ArxivQueryRun(api_wrapper=arxiv_wrapper)\n",
    "arxiv.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e38bda",
   "metadata": {},
   "source": [
    "- What it does: Creates an arXiv query tool that fetches short results (1 result, 200 chars max).\n",
    "- Analogy: A research alert service the librarian can query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "453cb3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\USER\\\\anaconda3\\\\envs\\\\textS\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200)),\n",
       " Tool(name='langsmith_search', description='Search for information about LangSmith. For any questions about LangSmith, you must use this tool!', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000020FE4651E40>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000020FE7300440>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000020FE4666E80>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000020FE7300440>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tools list\n",
    "tools=[wiki,arxiv,retriever_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498e0536",
   "metadata": {},
   "source": [
    "- **What it does:** Groups all tools the agent can use.\n",
    "- **Analogy:** The librarian’s toolbox: encyclopedia, research database, internal docs cabinet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f02fd",
   "metadata": {},
   "source": [
    "#### **Load environment, LLM selection (OpenAI commented out later)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bcd1bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "load_dotenv()\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "llm = ChatOllama(model=\"llama3.2:3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fe435a",
   "metadata": {},
   "source": [
    "- **What it does:** Loads `.env` (if you plan to use OpenAI later). Creates a local Ollama LLM (`llama3.2:3b`) for generation. The OpenAI LLM line is present but commented out (you asked to keep it).\n",
    "- Analogy: The librarian can either call an online expert (OpenAI) — commented out for now — or use a capable in-house expert (local Llama)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54cd0ec",
   "metadata": {},
   "source": [
    "#### **Pull a prompt from LangChain hub**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6db81e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "# Get the prompt to use - you can modify this!\n",
    "# prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "# prompt.messages\n",
    "\n",
    "# Pull the ReAct Prompt\n",
    "# Get the ReAct prompt template from the hub\n",
    "prompt = hub.pull(\"hwchase17/react\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d69ffa",
   "metadata": {},
   "source": [
    "- **What it does:** Downloads a prebuilt agent prompt (sets of instructions + function-call schema) from LangChain Hub.\n",
    "- **Analogy:** You hand the librarian a prewritten template that says “when a user asks X, do Y.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0e158c",
   "metadata": {},
   "source": [
    "#### **Create an agent that can call external tools**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c792b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Agents\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "from langchain.agents import create_tool_calling_agent\n",
    "from langchain.agents import create_react_agent\n",
    "\n",
    "#agent=create_openai_tools_agent(llm,tools,prompt)\n",
    "#agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "agent = create_react_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927a5285",
   "metadata": {},
   "source": [
    "- **What it does:** Builds an agent wired to the given LLM and tools, guided by the prompt. Note: the function is named `create_openai_tools_agent` but can often accept other LLMs (some versions expect an OpenAI LLM — if it errors, use a generic tools agent creator or the community-specific agent creation).\n",
    "\n",
    "- `create_openai_tools_agent()` = built specifically for OpenAI-style models (`gpt-3.5-turbo`, `gpt-4-turbo`, etc.).\n",
    "- `create_tool_calling_agent()` = general-purpose, works with Ollama, Anthropic, or any chat model that doesn’t strictly follow OpenAI’s schema.\n",
    "\n",
    "- **Analogy:** You hire a librarian who knows when to consult which tool and how to synthesize answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fe2168",
   "metadata": {},
   "source": [
    "#### **Wrap agent for execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e20698b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_log_to_str(x['intermediate_steps']))\n",
       "})\n",
       "| PromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={}, partial_variables={'tools': 'wikipedia - A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\narxiv - A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.\\nlangsmith_search(query: \\'str\\', *, retriever: \\'BaseRetriever\\' = VectorStoreRetriever(tags=[\\'FAISS\\', \\'OllamaEmbeddings\\'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000020FE7300440>, search_kwargs={}), document_prompt: \\'BasePromptTemplate\\' = PromptTemplate(input_variables=[\\'page_content\\'], input_types={}, partial_variables={}, template=\\'{page_content}\\'), document_separator: \\'str\\' = \\'\\\\n\\\\n\\', callbacks: \\'Callbacks\\' = None, response_format: \"Literal[\\'content\\', \\'content_and_artifact\\']\" = \\'content\\') -> \\'Union[str, tuple[str, list[Document]]]\\' - Search for information about LangSmith. For any questions about LangSmith, you must use this tool!', 'tool_names': 'wikipedia, arxiv, langsmith_search'}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
       "| RunnableBinding(bound=ChatOllama(model='llama3.2:3b'), kwargs={'stop': ['\\nObservation']}, config={}, config_factories=[])\n",
       "| ReActSingleInputOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\USER\\\\anaconda3\\\\envs\\\\textS\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=200)), ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200)), Tool(name='langsmith_search', description='Search for information about LangSmith. For any questions about LangSmith, you must use this tool!', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x0000020FE4651E40>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000020FE7300440>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x0000020FE4666E80>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000020FE7300440>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Agent Executer\n",
    "from langchain.agents import AgentExecutor\n",
    "agent_executor=AgentExecutor(agent=agent,tools=tools,verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46525e59",
   "metadata": {},
   "source": [
    "- **What it does:** `AgentExecutor` manages the agent run — it handles tool calls, the LLM’s thinking, and returns answers. You then call `.invoke()` to ask questions.\n",
    "- **Analogy:** Press a button and the librarian runs the whole process and returns the reply."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11382715",
   "metadata": {},
   "source": [
    "#### **Example queries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "083ee0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: Tell me about LangSmith\n",
      "Thought: To answer this question, I should use the langsmith_search tool since it's specifically designed for searching information related to Langsmith.\n",
      "Action: langsmith_search\n",
      "Action Input: query='Langsmith'\u001b[0m\u001b[38;5;200m\u001b[1;3mIt helps you trace requests, evaluate outputs, test prompts, and manage deployments in one place.\n",
      "LangSmith is framework agnostic, so you can use it with or without LangChain’s open-source libraries\n",
      "langchain and langgraph.\n",
      "Prototype locally, then move to production with integrated monitoring and evaluation to build more reliable AI systems.\n",
      "​Get started\n",
      "Create an accountSign up at smith.langchain.com (no credit card required).\n",
      "You can log in with Google, GitHub, or email.Create an API keyGo to your Settings page → API Keys → Create API Key.\n",
      "Copy the key and save it securely.\n",
      "Once your account and API key are ready, choose a quickstart to begin building with LangSmith:\n",
      "\n",
      "Copy the key and save it securely.\n",
      "Once your account and API key are ready, choose a quickstart to begin building with LangSmith:\n",
      "ObservabilityGain visibility into every step your application takes to debug faster and improve reliability.Start tracingEvaluationMeasure and track quality over time to ensure your AI applications are consistent and trustworthy.Evaluate your appDeploymentDeploy your agents as LangGraph Servers, ready to scale in production.Deploy your agentsPrompt TestingIterate on prompts with built-in versioning and collaboration to ship improvements faster.Test your promptsStudioUse a visual interface to design, test, and refine applications end-to-end.Develop with StudioHostingHost LangSmith in the cloud, in your environment, or hybrid to match your infrastructure and compliance needs.Choose your hosting mode\n",
      "​Workflow\n",
      "LangSmith combines observability, evaluation, deployment, and hosting in one integrated workflow—from local development to production.\n",
      "\n",
      "LangSmith docs - Docs by LangChainSkip to main contentLangGraph Platform is now part of LangSmith. Check out the Changelog for more information.Docs by LangChain home pageLangSmithSearch...⌘KGitHubTry LangSmithTry LangSmithSearch...NavigationLangSmith docsGet startedObservabilityEvaluationPrompt engineeringDeploymentHostingOverviewPlansCreate an account and API keyAccount administrationOverviewSet up a workspaceManage organizations using the APIManage billingSet up resource tagsUser managementReferenceLangSmith Python SDKLangSmith JS/TS SDKLangGraph Python SDKLangGraph JS/TS SDKLangSmith APILangGraph Server APIControl Plane API for LangSmith DeploymentAdditional resourcesReleases & changelogsData managementAuthentication methodsFAQsRegions FAQPricing FAQLangSmith docsCopy pageCopy pageLangSmith provides tools for developing, debugging, and deploying LLM applications.\n",
      "It helps you trace requests, evaluate outputs, test prompts, and manage deployments in one place.\n",
      "\n",
      "Edit the source of this page on GitHub⌘IWas this page helpful?YesNoPricing plansNextDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: Tell me about LangSmith\n",
      "Thought: To answer this question, I should use the langsmith_search tool since it's specifically designed for searching information related to Langsmith.\n",
      "Action: langsmith_search\n",
      "Action Input: query='Langsmith'\u001b[0m\u001b[38;5;200m\u001b[1;3mIt helps you trace requests, evaluate outputs, test prompts, and manage deployments in one place.\n",
      "LangSmith is framework agnostic, so you can use it with or without LangChain’s open-source libraries\n",
      "langchain and langgraph.\n",
      "Prototype locally, then move to production with integrated monitoring and evaluation to build more reliable AI systems.\n",
      "​Get started\n",
      "Create an accountSign up at smith.langchain.com (no credit card required).\n",
      "You can log in with Google, GitHub, or email.Create an API keyGo to your Settings page → API Keys → Create API Key.\n",
      "Copy the key and save it securely.\n",
      "Once your account and API key are ready, choose a quickstart to begin building with LangSmith:\n",
      "\n",
      "Copy the key and save it securely.\n",
      "Once your account and API key are ready, choose a quickstart to begin building with LangSmith:\n",
      "ObservabilityGain visibility into every step your application takes to debug faster and improve reliability.Start tracingEvaluationMeasure and track quality over time to ensure your AI applications are consistent and trustworthy.Evaluate your appDeploymentDeploy your agents as LangGraph Servers, ready to scale in production.Deploy your agentsPrompt TestingIterate on prompts with built-in versioning and collaboration to ship improvements faster.Test your promptsStudioUse a visual interface to design, test, and refine applications end-to-end.Develop with StudioHostingHost LangSmith in the cloud, in your environment, or hybrid to match your infrastructure and compliance needs.Choose your hosting mode\n",
      "​Workflow\n",
      "LangSmith combines observability, evaluation, deployment, and hosting in one integrated workflow—from local development to production.\n",
      "\n",
      "LangSmith docs - Docs by LangChainSkip to main contentLangGraph Platform is now part of LangSmith. Check out the Changelog for more information.Docs by LangChain home pageLangSmithSearch...⌘KGitHubTry LangSmithTry LangSmithSearch...NavigationLangSmith docsGet startedObservabilityEvaluationPrompt engineeringDeploymentHostingOverviewPlansCreate an account and API keyAccount administrationOverviewSet up a workspaceManage organizations using the APIManage billingSet up resource tagsUser managementReferenceLangSmith Python SDKLangSmith JS/TS SDKLangGraph Python SDKLangGraph JS/TS SDKLangSmith APILangGraph Server APIControl Plane API for LangSmith DeploymentAdditional resourcesReleases & changelogsData managementAuthentication methodsFAQsRegions FAQPricing FAQLangSmith docsCopy pageCopy pageLangSmith provides tools for developing, debugging, and deploying LLM applications.\n",
      "It helps you trace requests, evaluate outputs, test prompts, and manage deployments in one place.\n",
      "\n",
      "Edit the source of this page on GitHub⌘IWas this page helpful?YesNoPricing plansNextDocs by LangChain home pagegithubxlinkedinyoutubeResourcesForumChangelogLangChain AcademyTrust CenterCompanyAboutCareersBloggithubxlinkedinyoutubePowered by Mintlify\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: LangSmith is a framework-agnostic platform that provides tools for developing, debugging, and deploying Large Language Model (LLM) applications. It helps users trace requests, evaluate outputs, test prompts, and manage deployments in one place, offering observability, evaluation, prompt engineering, deployment, hosting, and workflow management capabilities.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about Langsmith',\n",
       " 'output': 'LangSmith is a framework-agnostic platform that provides tools for developing, debugging, and deploying Large Language Model (LLM) applications. It helps users trace requests, evaluate outputs, test prompts, and manage deployments in one place, offering observability, evaluation, prompt engineering, deployment, hosting, and workflow management capabilities.'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"Tell me about Langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b92b9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mQuestion: What is Machine Learning?\n",
      "\n",
      "Thought: I need to find a general definition of Machine Learning that applies to various fields.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: \"Machine learning\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: What is Machine Learning?\n",
      "Thought: I need to find a general definition of Machine Learning that applies to various fields.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: \"Machine learning\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mI'll follow the format you specified.\n",
      "\n",
      "Question: What is Machine Learning?\n",
      "Thought: I need to find a general definition of Machine Learning that applies to various fields.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: \"Machine learning\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: What is Machine Learning?\n",
      "Thought: I need to find a general definition of Machine Learning that applies to various fields.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: \"Machine learning\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: What is Machine Learning?\n",
      "Thought: I need to find a general definition of Machine Learning that applies to various fields.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: \"Machine learning\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: What is Machine Learning?\n",
      "Thought: I need to find a general definition of Machine Learning that applies to various fields.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: \"Machine learning\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mHere's my attempt to follow your format:\n",
      "\n",
      "Question: What is Machine Learning?\n",
      "Thought: I need to find a general definition of Machine Learning that applies to various fields.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: \"Machine learning\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: What is Machine Learning?\n",
      "Thought: I need to find a general definition of Machine Learning that applies to various fields.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: \"Machine learning\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: What is Machine Learning?\n",
      "Thought: I need to find a general definition of Machine Learning that applies to various fields.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: \"Machine learning\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: What is Machine Learning?\n",
      "Thought: I need to find a general definition of Machine Learning that applies to various fields.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: \"Machine learning\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: What is Machine Learning?\n",
      "Thought: I need to find a general definition of Machine Learning that applies to various fields.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: \"Machine learning\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: What is Machine Learning?\n",
      "\n",
      "Thought: I need to find a general definition of Machine Learning that applies to various fields.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: \"Machine learning\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: What is Machine Learning?\n",
      "\n",
      "Thought: I need to find a general definition of Machine Learning that applies to various fields.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: \"Machine learning\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: What is Machine Learning?\n",
      "Thought: I need to find a general definition of Machine Learning that applies to various fields.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: \"Machine learning\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: What is Machine Learning?\n",
      "Thought: I need to find a general definition of Machine Learning that applies to various fields.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: \"Machine learning\"\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and gen\u001b[0m\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is Machine Learning?',\n",
       " 'output': 'Agent stopped due to iteration limit or time limit.'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What is Machine Learning?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dd52a488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: arxiv\n",
      "Action Input: \"1605.08386\"\u001b[0m\u001b[33;1m\u001b[1;3mPublished: 2016-05-26\n",
      "Title: Heat-bath random walks with Markov bases\n",
      "Authors: Caprice Stanley, Tobias Windisch\n",
      "Summary: Graphs on lattice points are studied whose edges come from a finite set of\n",
      "allo\u001b[0m\u001b[32;1m\u001b[1;3mQuestion: What's the paper 1605.08386 about?\n",
      "Thought: I now know the final answer\n",
      "\n",
      "Final Answer: The paper \"Heat-bath random walks with Markov bases\" (1605.08386) is about studying graphs on lattice points whose edges come from a finite set of allowed transitions, and it was published in 2016 by authors Caprice Stanley and Tobias Windisch.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's the paper 1605.08386 about?\",\n",
       " 'output': 'The paper \"Heat-bath random walks with Markov bases\" (1605.08386) is about studying graphs on lattice points whose edges come from a finite set of allowed transitions, and it was published in 2016 by authors Caprice Stanley and Tobias Windisch.'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\":\"What's the paper 1605.08386 about?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2526e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565efc93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
